This file is a merged representation of the entire codebase, combined into a single document by Repomix.
The content has been processed where content has been compressed (code blocks are separated by ⋮---- delimiter).

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Content has been compressed - code blocks are separated by ⋮---- delimiter
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
ao-cli/
  src/
    opts/
      language.rs
      mod.rs
    build.rs
    check.rs
    config.rs
    init.rs
    lib.rs
    main.rs
    run.rs
    utils.rs
  .gitignore
  Cargo.toml
api-service/
  anops_pb2_grpc.py
  anops_pb2.py
  anops_pb2.pyi
  Dockerfile
  main.py
  README.md
  requirements.txt
model-interface/
  anops.proto
  README.md
model-service/
  anops_pb2_grpc.py
  anops_pb2.py
  anops_pb2.pyi
  Dockerfile
  README.md
  requirements.txt
  server.py
.repomixignore
ao.toml
docker-compose.yml
README.md
repomix.config.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="ao-cli/src/opts/language.rs">
pub enum Language {
</file>

<file path="ao-cli/src/opts/mod.rs">
pub mod language;
</file>

<file path="ao-cli/src/build.rs">
use std::path::Path;
⋮----
use crate::config;
⋮----
use crate::check; // Import the check module to run pre-build checks
⋮----
/// Handler for `ao build`.
/// Finds the project root, loads config, runs checks, and builds Docker images.
///
/// # Arguments
⋮----
/// * `path_str` - Path within the project directory to start searching from.
⋮----
/// # Errors
⋮----
/// Returns an error if the project root is not found, config loading fails,
/// checks fail, or any Docker build command fails.
pub fn run(path_str: String) -> Result<()> {
⋮----
println!("Starting build from '{}'", start_path.display());
⋮----
// Find project root
let project_path = find_project_root(start_path)
.with_context(|| format!("Failed to find project root starting from '{}'", start_path.display()))?;
println!("Found project root at '{}'", project_path.display());
⋮----
// Load configuration
⋮----
.context("Failed to load project configuration")?;
⋮----
println!("Building project: {}", project_name);
⋮----
// --- Pre-build Checks --- //
println!("--- Running Pre-Build Checks ---");
// Use the existing check::run function
check::run(path_str.clone()) // Pass the original path string
.context("Pre-build checks failed")?;
println!("--- Pre-Build Checks Passed ---");
⋮----
// --- Build Docker Images --- //
println!("--- Building Docker Images ---");
⋮----
// Define image names (using project name from config)
// TODO: Allow overriding tags/names via config or CLI args later
let api_image_name = format!("{}-api-service:latest", project_name);
let model_image_name = format!("{}-model-service:latest", project_name);
⋮----
// Build api-service
let api_service_path = project_path.join("api-service");
if api_service_path.exists() && api_service_path.is_dir() {
println!("Building {}...", api_image_name);
let build_cmd = format!(
⋮----
run_tool(&build_cmd, &api_service_path)
.with_context(|| format!("Failed to build api-service image: {}", api_image_name))?;
println!("Successfully built {}", api_image_name);
⋮----
println!("Skipping api-service build: directory not found at {:?}", api_service_path);
⋮----
// Build model-service
let model_service_path = project_path.join("model-service");
if model_service_path.exists() && model_service_path.is_dir() {
println!("Building {}...", model_image_name);
// Note: This assumes the Docker context is the model-service directory itself.
// If generated gRPC code needs to be included from model-interface,
// the Dockerfile or build process might need adjustment (e.g., copying files before build).
⋮----
run_tool(&build_cmd, &model_service_path)
.with_context(|| format!("Failed to build model-service image: {}", model_image_name))?;
println!("Successfully built {}", model_image_name);
⋮----
println!("Skipping model-service build: directory not found at {:?}", model_service_path);
⋮----
println!("--- Docker Images Built Successfully ---");
⋮----
Ok(())
⋮----
// TODO: Add tests for build::run
// - Test success case (mocks docker build or requires docker)
// - Test failure if check::run fails
// - Test failure if docker build fails
// - Test finding root from subdir
</file>

<file path="ao-cli/src/check.rs">
use std::fs;
⋮----
use crate::config; // Import the config module
use crate::utils::{find_project_root, run_tool}; // Import from utils
⋮----
/// Handler for `ao check`.
/// Verifies structure, loads config, and runs configured linters/testers.
///
/// # Arguments
⋮----
/// * `path_str` - Path within the project directory to start searching from.
⋮----
/// # Errors
⋮----
/// Returns an error if any step (root finding, config load, structure check, tool execution) fails.
pub fn run(path_str: String) -> Result<()> {
⋮----
println!("Starting check from '{}'", start_path.display());
⋮----
// Find project root
let project_path = find_project_root(start_path)
.with_context(|| format!("Failed to find project root starting from '{}'", start_path.display()))?;
println!("Found project root at '{}'", project_path.display());
⋮----
// Load configuration
⋮----
.context("Failed to load project configuration")?;
println!("Project name from config: {}", config.project.name);
⋮----
// --- Structure Checks --- //
println!("Running structure checks in '{}'", project_path.display());
⋮----
// Check for required directories relative to the found project root
// TODO: Enhance check to include service directories // Updated below
⋮----
// Keep original basic checks? Decide if they are still relevant
// "models",
// "tests",
// "notebooks",
⋮----
for dir_name in required_dirs.iter() {
let dir_path = project_path.join(dir_name);
if !dir_path.exists() {
bail!(
⋮----
if !dir_path.is_dir() {
bail!("Path '{}' is not a directory.", dir_path.display());
⋮----
println!("Found directory: {:?}", dir_path);
⋮----
// Check for specific required files within service directories
⋮----
("api-service", "requirements.txt"), // Good practice to check
("api-service", "anops_pb2.py"), // Check for generated gRPC file
("api-service", "anops_pb2_grpc.py"), // Check for generated gRPC file
⋮----
("model-service", "requirements.txt"), // Good practice to check
("model-service", "anops_pb2.py"), // Check for generated gRPC file
("model-service", "anops_pb2_grpc.py"), // Check for generated gRPC file
⋮----
for (dir_name, file_name) in required_files.iter() {
let file_path = project_path.join(dir_name).join(file_name);
if !file_path.exists() {
⋮----
if !file_path.is_file() {
bail!("Path '{}' is not a file.", file_path.display());
⋮----
println!("Found file: {:?}", file_path);
⋮----
// Config file presence is already checked by find_project_root and load_config
println!("Found config file: {:?}", project_path.join("ao.toml"));
⋮----
// --- Tool Execution --- //
⋮----
// Run configured linters
if !config.check.linters.is_empty() {
println!("--- Running Linters ---");
⋮----
run_tool(linter_cmd, &project_path)
.with_context(|| format!("Linter command '{}' failed", linter_cmd))?;
⋮----
println!("--- Linters Finished ---");
⋮----
println!("No linters configured.");
⋮----
// Run configured testers
if !config.check.testers.is_empty() {
println!("--- Running Testers ---");
⋮----
run_tool(tester_cmd, &project_path)
.with_context(|| format!("Tester command '{}' failed", tester_cmd))?;
⋮----
println!("--- Testers Finished ---");
⋮----
println!("No testers configured.");
⋮----
println!("All checks passed successfully!");
Ok(())
⋮----
mod tests {
⋮----
use crate::init;
⋮----
use tempfile::tempdir;
⋮----
// Helper to create a valid project structure for testing check
// Note: init::run already creates the required service structure
fn setup_valid_project(base_path: &Path) -> Result<PathBuf> {
⋮----
let project_path = base_path.join(project_name);
// Use init::run to create the structure
init::run(project_path.to_str().unwrap().to_string())
.context("init::run failed during test setup")?;
Ok(project_path)
⋮----
// Helper to add a [check] section to ao.toml
fn add_check_config(project_path: &Path) {
let config_path = project_path.join("ao.toml");
let mut content = fs::read_to_string(&config_path).unwrap();
content.push_str(
⋮----
fs::write(config_path, content).unwrap();
⋮----
fn find_project_root_finds_root() {
let tmp_dir = tempdir().unwrap();
let project_path = setup_valid_project(tmp_dir.path()).unwrap();
let models_path = project_path.join("models");
⋮----
// Search from root
let found_root = crate::utils::find_project_root(&project_path).unwrap(); // Use utils::find_project_root
assert_eq!(found_root, project_path);
⋮----
// Search from subdir
let found_root_from_subdir = crate::utils::find_project_root(&models_path).unwrap(); // Use utils::find_project_root
assert_eq!(found_root_from_subdir, project_path);
⋮----
fn find_project_root_fails_if_no_root() {
⋮----
let project_path = tmp_dir.path().join("no_config_project");
fs::create_dir(&project_path).unwrap();
⋮----
let result = crate::utils::find_project_root(&project_path); // Use utils::find_project_root
assert!(result.is_err());
assert!(result
⋮----
fn run_succeeds_when_called_from_root() {
⋮----
let result = run(project_path.to_str().unwrap().to_string());
assert!(result.is_ok());
⋮----
fn run_succeeds_when_called_from_subdir() {
⋮----
let models_path = project_path.join("models"); // 'models' dir is created by setup_valid_project via init::run
let result = run(models_path.to_str().unwrap().to_string());
⋮----
fn run_succeeds_with_check_config_present() {
⋮----
add_check_config(&project_path); // Add [check] section
⋮----
// We could capture stdout here to verify the print messages if needed
⋮----
fn run_fails_if_path_does_not_exist() {
⋮----
let project_path = tmp_dir.path().join("non_existent_project");
⋮----
// Error could be canonicalize failure or root finding failure
assert!(result.unwrap_err().to_string().contains("Failed to find project root") || result.unwrap_err().to_string().contains("Failed to canonicalize"));
⋮----
fn run_fails_if_no_project_found() {
⋮----
let empty_dir = tmp_dir.path().join("empty_dir");
fs::create_dir(&empty_dir).unwrap();
let result = run(empty_dir.to_str().unwrap().to_string());
⋮----
fn run_fails_if_config_is_malformed() {
⋮----
// Overwrite with malformed config
fs::write(project_path.join("ao.toml"), "[project]name=").unwrap();
⋮----
fn run_fails_if_structure_invalid_even_if_found() {
⋮----
// Test removing a required service directory
fs::remove_dir_all(project_path.join("api-service")).unwrap();
let result_dir = run(project_path.to_str().unwrap().to_string());
assert!(result_dir.is_err());
let err_msg_dir = result_dir.unwrap_err().to_string();
assert!(err_msg_dir.contains("Required directory"));
assert!(err_msg_dir.contains("api-service' not found"));
⋮----
// Recreate the project for the next check
let project_path = setup_valid_project(tmp_dir.path()).unwrap(); // Re-init
⋮----
// Test removing a required file within a service directory (proto)
fs::remove_file(project_path.join("model-interface/anops.proto")).unwrap();
let result_file_proto = run(project_path.to_str().unwrap().to_string());
assert!(result_file_proto.is_err());
let err_msg_proto = result_file_proto.unwrap_err().to_string();
assert!(err_msg_proto.contains("Required file"));
assert!(err_msg_proto.contains("anops.proto' not found in directory 'model-interface'"));
⋮----
// Test removing a generated gRPC file
fs::remove_file(project_path.join("api-service/anops_pb2.py")).unwrap();
let result_file_grpc = run(project_path.to_str().unwrap().to_string());
assert!(result_file_grpc.is_err());
let err_msg_grpc = result_file_grpc.unwrap_err().to_string();
assert!(err_msg_grpc.contains("Required file"));
assert!(err_msg_grpc.contains("anops_pb2.py' not found in directory 'api-service'"));
</file>

<file path="ao-cli/src/config.rs">
use serde::Deserialize;
⋮----
use std::fs;
use std::path::Path;
use std::collections::HashMap; // Added HashMap
⋮----
/// Represents the overall configuration loaded from ao.toml
⋮----
pub struct Config {
⋮----
#[serde(default)] // Use default HashMap if missing
⋮----
/// Represents the [project] table in ao.toml
#[derive(Deserialize, Debug, PartialEq, Default)] // Added Default
pub struct ProjectConfig {
⋮----
/// Represents the [check] table in ao.toml
⋮----
pub struct CheckConfig {
⋮----
/// Loads the configuration from the ao.toml file in the project root.
///
/// # Arguments
⋮----
/// * `project_root` - The path to the project root directory (containing ao.toml).
⋮----
/// # Errors
⋮----
/// Returns an error if the config file cannot be read or parsed.
pub fn load_config(project_root: &Path) -> Result<Config> {
let config_path = project_root.join("ao.toml");
println!("Loading config from: {:?}", config_path);
⋮----
if !config_path.exists() {
⋮----
.with_context(|| format!("Failed to read config file: {}", config_path.display()))?;
⋮----
.with_context(|| format!("Failed to parse TOML config file: {}", config_path.display()))?;
⋮----
println!("Config loaded successfully: {:?}", config);
Ok(config)
⋮----
mod tests {
⋮----
use tempfile::tempdir;
⋮----
use std::path::PathBuf;
⋮----
// Helper to create a dummy ao.toml
fn create_dummy_config(dir: &Path, content: &str) -> PathBuf {
let config_path = dir.join("ao.toml");
fs::write(&config_path, content).unwrap();
⋮----
fn load_config_succeeds_with_valid_file_no_extras() {
let tmp_dir = tempdir().unwrap();
⋮----
let config_content = format!("[project]\nname = \"{}\"", project_name);
create_dummy_config(tmp_dir.path(), &config_content);
⋮----
let config = load_config(tmp_dir.path()).unwrap();
⋮----
assert_eq!(config.project.name, project_name);
assert_eq!(config.check, CheckConfig::default());
assert!(config.tasks.is_empty()); // Default tasks is empty map
⋮----
fn load_config_succeeds_with_tasks_section() {
⋮----
let config_content = format!("[project]\nname = \"{}\"\n\n[tasks]\nbuild = [\"echo building...\", \"mkdir dist\"]\ndeploy = [\"echo deploying...\"]", project_name);
⋮----
assert_eq!(config.tasks.len(), 2);
assert_eq!(config.tasks.get("build").unwrap(), &vec!["echo building...", "mkdir dist"]);
assert_eq!(config.tasks.get("deploy").unwrap(), &vec!["echo deploying..."]);
⋮----
fn load_config_succeeds_with_empty_tasks_section() {
⋮----
let config_content = format!("[project]\nname = \"{}\"\n\n[tasks] # Empty tasks table", project_name);
⋮----
assert!(config.tasks.is_empty());
⋮----
fn load_config_succeeds_with_all_sections() {
⋮----
let config_content = format!("[project]\nname = \"{}\"\n\n[check]\nlinters = [\"lint1\"]\n\n[tasks]\nbuild = [\"build1\"]", project_name);
⋮----
assert_eq!(config.check.linters, vec!["lint1"]);
assert!(config.check.testers.is_empty());
assert_eq!(config.tasks.len(), 1);
assert_eq!(config.tasks.get("build").unwrap(), &vec!["build1"]);
⋮----
fn load_config_fails_with_malformed_tasks() {
⋮----
// Task steps should be an array of strings
let config_content = format!("[project]\nname = \"{}\"\n\n[tasks]\nbuild = \"not-an-array\"", project_name);
⋮----
let result = load_config(tmp_dir.path());
assert!(result.is_err());
assert!(result.unwrap_err().to_string().contains("invalid type: string \"not-an-array\", expected table")); // TOML expects table for tasks.build
⋮----
fn load_config_fails_with_malformed_task_steps() {
⋮----
let config_content = format!("[project]\nname = \"{}\"\n\n[tasks]\nbuild = [1, 2, 3] # Numbers instead of strings", project_name);
⋮----
assert!(result.unwrap_err().to_string().contains("invalid type: integer `1`, expected a string"));
⋮----
fn load_config_fails_if_file_missing() {
⋮----
assert!(result.unwrap_err().to_string().contains("Configuration file not found"));
⋮----
fn load_config_fails_if_file_malformed() {
⋮----
create_dummy_config(tmp_dir.path(), malformed_content);
⋮----
assert!(result.unwrap_err().to_string().contains("Failed to parse TOML config file"));
⋮----
fn load_config_fails_if_missing_project_table() {
⋮----
let content = "[tasks]\nbuild=['a']"; // Missing [project]
create_dummy_config(tmp_dir.path(), content);
⋮----
assert!(result.unwrap_err().to_string().contains("missing field `project`"));
⋮----
fn load_config_fails_if_missing_project_name() {
⋮----
assert!(result.unwrap_err().to_string().contains("missing field `name`"));
⋮----
fn load_config_handles_incorrect_types_in_check() {
⋮----
let config_content = format!("[project]\nname = \"{}\"\n\n[check]\nlinters = \"not-an-array\" # Incorrect type", project_name);
⋮----
assert!(result.unwrap_err().to_string().contains("invalid type: string \"not-an-array\", expected a sequence"));
</file>

<file path="ao-cli/src/init.rs">
use std::fs;
use std::path::Path;
⋮----
// Basic placeholder content for generated files
⋮----
/// Handler for `ao init`.
/// Creates the basic project directory structure and configuration file.
///
/// # Arguments
⋮----
/// * `name` - The name of the project directory to initialize.
⋮----
/// # Errors
⋮----
/// Returns an error if initialization fails (e.g., directory creation, file creation).
pub fn run(name: String) -> Result<()> {
⋮----
println!("Initializing project '{}' at {:?}", name, project_path);
⋮----
// Create base directory
⋮----
.with_context(|| format!("Failed to create project directory: {}", project_path.display()))?;
println!("Created directory: {:?}", project_path);
⋮----
// Create standard subdirectories
⋮----
for subdir in subdirs.iter() {
let dir_path = project_path.join(subdir);
⋮----
.with_context(|| format!("Failed to create subdirectory: {}", dir_path.display()))?;
println!("Created directory: {:?}", dir_path);
⋮----
// Create ao.toml configuration file
let config_path = project_path.join("ao.toml");
let config_content = DEFAULT_AO_TOML_CONTENT.replace("{}", &name); // Basic placeholder, replace name
⋮----
.with_context(|| format!("Failed to write config file: {}", config_path.display()))?;
println!("Created config file: {:?}", config_path);
⋮----
// Create .gitignore
let gitignore_path = project_path.join(".gitignore");
⋮----
.with_context(|| format!("Failed to write .gitignore file: {}", gitignore_path.display()))?;
println!("Created file: {:?}", gitignore_path);
⋮----
// Create Dockerfiles
let api_dockerfile_path = project_path.join("api-service/Dockerfile");
⋮----
.with_context(|| format!("Failed to write api-service Dockerfile: {}", api_dockerfile_path.display()))?;
println!("Created file: {:?}", api_dockerfile_path);
⋮----
let model_dockerfile_path = project_path.join("model-service/Dockerfile");
⋮----
.with_context(|| format!("Failed to write model-service Dockerfile: {}", model_dockerfile_path.display()))?;
println!("Created file: {:?}", model_dockerfile_path);
⋮----
// Create docker-compose.yml
let compose_path = project_path.join("docker-compose.yml");
⋮----
.with_context(|| format!("Failed to write docker-compose.yml: {}", compose_path.display()))?;
println!("Created file: {:?}", compose_path);
⋮----
// Create model-interface proto file
let proto_path = project_path.join("model-interface/anops.proto");
⋮----
.with_context(|| format!("Failed to write anops.proto: {}", proto_path.display()))?;
println!("Created file: {:?}", proto_path);
⋮----
// Create READMEs
let api_readme_path = project_path.join("api-service/README.md");
⋮----
.with_context(|| format!("Failed to write api-service README: {}", api_readme_path.display()))?;
println!("Created file: {:?}", api_readme_path);
⋮----
let model_readme_path = project_path.join("model-service/README.md");
⋮----
.with_context(|| format!("Failed to write model-service README: {}", model_readme_path.display()))?;
println!("Created file: {:?}", model_readme_path);
⋮----
let interface_readme_path = project_path.join("model-interface/README.md");
⋮----
.with_context(|| format!("Failed to write model-interface README: {}", interface_readme_path.display()))?;
println!("Created file: {:?}", interface_readme_path);
⋮----
// Create placeholder files in services (optional, but good practice)
// e.g., api-service/main.py, model-service/server.py
// fs::write(project_path.join("api-service/main.py"), "# FastAPI app placeholder")?;
// fs::write(project_path.join("model-service/server.py"), "# gRPC server placeholder")?;
⋮----
println!("Project '{}' initialized successfully.", name);
println!("Next steps:");
println!("  - cd {}", name);
println!("  - Review READMEs in api-service, model-service, model-interface.");
println!("  - Implement your model in model-service.");
println!("  - Implement the API endpoints in api-service.");
println!("  - Generate gRPC code (see model-interface/README.md).");
println!("  - Configure dependencies (e.g., requirements.txt).");
println!("  - Run 'docker-compose up --build' to build and start services.");
⋮----
Ok(())
⋮----
mod tests {
⋮----
use tempfile::tempdir;
⋮----
fn run_succeeds_and_creates_structure() {
let tmp_dir = tempdir().unwrap();
⋮----
// Run the init command relative to the temp dir
let result = run(tmp_dir.path().join(project_name).to_str().unwrap().to_string());
assert!(result.is_ok());
⋮----
let project_path = tmp_dir.path().join(project_name);
⋮----
// Check if base directory exists
assert!(project_path.exists());
assert!(project_path.is_dir());
⋮----
// Check if standard subdirectories exist
⋮----
assert!(dir_path.exists(), "Directory missing: {}", subdir);
assert!(dir_path.is_dir(), "Path is not a directory: {}", subdir);
⋮----
// Check if core files exist
⋮----
for file in core_files.iter() {
let file_path = project_path.join(file);
assert!(file_path.exists(), "File missing: {}", file);
assert!(file_path.is_file(), "Path is not a file: {}", file);
⋮----
// Check if config file has basic content
⋮----
let content = fs::read_to_string(config_path).unwrap();
assert!(content.contains(&format!("[project]
⋮----
// Check .gitignore content (basic check)
⋮----
let gitignore_content = fs::read_to_string(gitignore_path).unwrap();
assert!(gitignore_content.contains("__pycache__/"));
assert!(gitignore_content.contains("*.pyc"));
⋮----
// Clean up is handled by tempdir dropping
⋮----
fn run_fails_if_cannot_create_dir() {
// This test is tricky because permissions are hard to simulate reliably
// across platforms in a unit test without running as root or modifying
// system state. We rely on the OS preventing creation in restricted areas.
// Trying to create directly in `/` (on Unix-like systems) might fail
// without root privileges.
if cfg!(unix) {
⋮----
// Attempt to run the init command in a restricted path
let result = run(project_name.to_string());
// We expect this to fail, likely with a permission error context.
assert!(result.is_err());
assert!(result.unwrap_err().to_string().contains("Failed to create project directory"));
⋮----
// Skip this specific scenario on non-Unix platforms where
// root directory permissions might behave differently.
println!("Skipping root directory creation test on non-Unix platform.");
</file>

<file path="ao-cli/src/lib.rs">
pub mod init;
pub mod check;
pub mod config;
pub mod run;
pub mod utils;
pub mod build; // Add the build module
</file>

<file path="ao-cli/src/main.rs">
use anyhow::Result;
⋮----
use ao::{init, check, run, build}; // Added build
⋮----
/// Top-level CLI parser
⋮----
struct Cli {
⋮----
/// Available subcommands
⋮----
enum Commands {
/// Initialize a new modeling project
⋮----
/// Name of the project to initialize
⋮----
/// Run linting and tests on a project
⋮----
/// Path to the project directory
⋮----
/// Run a defined task from ao.toml
⋮----
/// Name of the task to run
⋮----
/// Path within the project directory (optional, defaults to current dir)
⋮----
/// Build Docker images for the project services
⋮----
fn main() -> Result<()> {
⋮----
Commands::Build { path } => build::run(path)?, // Add handler for Build
⋮----
Ok(())
</file>

<file path="ao-cli/src/run.rs">
use crate::config;
⋮----
use std::env;
⋮----
use crate::utils::{find_project_root, run_tool}; // Import from utils
⋮----
// --- Helper Functions removed, now in utils.rs --- //
⋮----
// --- Main `run` function --- //
⋮----
/// Handler for `ao run <task_name>`.
/// Finds the project root, loads config, and executes the steps for the specified task.
///
/// # Arguments
⋮----
/// * `task_name` - The name of the task defined in `ao.toml` to execute.
/// * `path_str` - Path within the project directory to start searching from.
⋮----
/// # Errors
⋮----
/// Returns an error if the project root is not found, config loading fails,
/// the task is not found, or any command within the task fails.
pub fn run(task_name: String, path_str: String) -> Result<()> {
⋮----
println!(
⋮----
// Find project root using the utility function
let project_path = find_project_root(start_path)
.with_context(|| format!("Failed to find project root starting from '{}'", start_path.display()))?;
println!("Found project root at '{}'", project_path.display());
⋮----
// Load configuration
⋮----
.context("Failed to load project configuration")?;
println!("Project name from config: {}", config.project.name);
⋮----
// Find the requested task
match config.tasks.get(&task_name) {
⋮----
println!("--- Running task '{}' ---", task_name);
if commands.is_empty() {
println!("Task '{}' has no commands defined.", task_name);
⋮----
// Use the utility function to run the command
run_tool(command_str, &project_path).with_context(|| {
format!("Command '{}' in task '{}' failed", command_str, task_name)
⋮----
println!("--- Task '{}' finished successfully ---", task_name);
Ok(())
⋮----
bail!("Task '{}' not found in ao.toml", task_name);
⋮----
mod tests {
⋮----
use crate::init; // To set up a project structure
use std::fs;
use tempfile::tempdir;
⋮----
// Helper to create a project with a specific ao.toml content
fn setup_project_with_config(base_path: &Path, config_content: &str) -> Result<PathBuf> {
let project_dir = base_path.join("test_run_project");
// Run init first to get base structure (it creates a basic ao.toml)
init::run(project_dir.to_str().unwrap().to_string())?;
// Overwrite ao.toml with specific content
let config_path = project_dir.join("ao.toml");
fs::write(config_path, config_content).context("Failed to write test config")?;
Ok(project_dir)
⋮----
fn run_succeeds_with_valid_task() {
let tmp_dir = tempdir().unwrap();
let project_name = "test_run_project"; // Name used inside config content
let config_content = format!(
⋮----
let project_path = setup_project_with_config(tmp_dir.path(), &config_content).unwrap();
⋮----
let result = run("build".to_string(), project_path.to_str().unwrap().to_string());
⋮----
assert!(result.is_ok());
// Check side effect of the command
assert!(project_path.join("build_output").exists());
assert!(project_path.join("build_output").is_dir());
⋮----
fn run_succeeds_with_empty_task() {
⋮----
let result = run("empty".to_string(), project_path.to_str().unwrap().to_string());
⋮----
// No side effects to check
⋮----
fn run_fails_if_task_not_found() {
⋮----
let result = run("deploy".to_string(), project_path.to_str().unwrap().to_string()); // Task 'deploy' doesn't exist
⋮----
assert!(result.is_err());
assert!(result
⋮----
fn run_fails_if_command_in_task_fails() {
⋮----
// Use a command that will fail (ls on a non-existent file)
⋮----
let err_msg = result.unwrap_err().to_string();
// Check that the error context includes the failing command and task name
assert!(err_msg.contains("Command 'ls non_existent_file_in_task' in task 'build' failed"));
// Also check the underlying error from run_tool
assert!(err_msg.contains("Tool 'ls non_existent_file_in_task' failed with status"));
⋮----
fn run_fails_if_project_root_not_found() {
⋮----
// Don't create any project or config
let non_project_path = tmp_dir.path().join("not_a_project");
fs::create_dir(&non_project_path).unwrap();
⋮----
let result = run(
"build".to_string(),
non_project_path.to_str().unwrap().to_string(),
⋮----
fn run_fails_if_config_is_malformed() {
⋮----
// Create a project but with invalid TOML
let project_path = tmp_dir.path().join("malformed_config_project");
init::run(project_path.to_str().unwrap().to_string()).unwrap();
fs::write(project_path.join("ao.toml"), "[project]name=").unwrap(); // Malformed
⋮----
fn run_works_when_called_from_subdir() {
⋮----
let models_path = project_path.join("models"); // Subdir created by init
⋮----
// Run from the 'models' subdirectory
let result = run("build".to_string(), models_path.to_str().unwrap().to_string());
⋮----
// Check side effect relative to the project root
assert!(project_path.join("build_output_subdir").exists());
assert!(project_path.join("build_output_subdir").is_dir());
</file>

<file path="ao-cli/src/utils.rs">
/// Searches upwards from the starting path for a file named `ao.toml`.
/// Returns the path to the directory containing `ao.toml` if found.
pub fn find_project_root(start_path: &Path) -> Result<PathBuf> {
println!("find_project_root: Starting search from '{}'", start_path.display()); // Added log
// Canonicalize the starting path to resolve symlinks and relative components
⋮----
.canonicalize()
.with_context(|| format!("Failed to canonicalize path: {}", start_path.display()))?;
println!("find_project_root: Canonical path is '{}'", current_path.display()); // Added log
⋮----
let config_path = current_path.join("ao.toml");
println!("find_project_root: Checking for config at '{}'", config_path.display()); // Added log
if config_path.exists() && config_path.is_file() {
println!("find_project_root: Found config at '{}'", config_path.display()); // Added log
return Ok(current_path);
⋮----
// Move up to the parent directory
if let Some(parent) = current_path.parent() {
// Check if we are already at the root to prevent infinite loop
⋮----
println!("find_project_root: Reached filesystem root, config not found."); // Added log
⋮----
println!("find_project_root: Moving up to parent '{}'", parent.display()); // Added log
current_path = parent.to_path_buf();
⋮----
// Should not happen if parent == current_path check works, but as a safeguard
println!("find_project_root: No parent found, config not found."); // Added log
⋮----
// If loop finishes without returning, the file was not found
bail!(
⋮----
/// Executes an external tool/command within the project directory.
///
/// # Arguments
⋮----
/// * `command_str` - The command string to execute (e.g., "ruff check .").
/// * `project_root` - The path to the project root directory, used as the working directory.
⋮----
/// # Errors
⋮----
/// Returns an error if the command cannot be executed or if it exits with a non-zero status.
pub fn run_tool(command_str: &str, project_root: &Path) -> Result<()> {
println!(
⋮----
if command_str.is_empty() {
bail!("Cannot run an empty command string.");
⋮----
// Basic command parsing (split by space, handle potential quotes later if needed)
let parts: Vec<&str> = command_str.split_whitespace().collect();
if parts.is_empty() {
⋮----
command.args(args);
command.current_dir(project_root);
command.stdout(Stdio::inherit()); // Stream stdout directly
command.stderr(Stdio::inherit()); // Stream stderr directly
⋮----
.status()
.with_context(|| format!("Failed to execute command: '{}'", command_str))?;
⋮----
if status.success() {
println!("Tool '{}' finished successfully.", command_str);
Ok(())
⋮----
bail!("Tool '{}' failed with status: {}", command_str, status);
</file>

<file path="ao-cli/.gitignore">
/target
entire-codebase.xml
repomix.config.json
.repomixignore
</file>

<file path="ao-cli/Cargo.toml">
[package]
name = "ao"
version = "0.1.0"
edition = "2021"

[dependencies]
clap = { version = "4.2", features = ["derive"] }
anyhow = "1.0"
toml = "0.8" # Added for TOML parsing
serde = { version = "1.0", features = ["derive"] } # Added for deserialization

[dev-dependencies]
tempfile = "3.10"
</file>

<file path="api-service/anops_pb2_grpc.py">
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
⋮----
GRPC_GENERATED_VERSION = '1.71.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False
⋮----
_version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
⋮----
_version_not_supported = True
⋮----
class AnOpsStub(object)
⋮----
"""The AnOps service definition.
    """
⋮----
def __init__(self, channel)
⋮----
"""Constructor.

        Args:
            channel: A grpc.Channel.
        """
⋮----
class AnOpsServicer(object)
⋮----
def Predict(self, request, context)
⋮----
"""Sends input data for prediction.
        """
⋮----
def add_AnOpsServicer_to_server(servicer, server)
⋮----
rpc_method_handlers = {
generic_handler = grpc.method_handlers_generic_handler(
⋮----
# This class is part of an EXPERIMENTAL API.
class AnOps(object)
</file>

<file path="api-service/anops_pb2.py">
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: anops.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
⋮----
# @@protoc_insertion_point(imports)
⋮----
_sym_db = _symbol_database.Default()
⋮----
DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0b\x61nops.proto\x12\x05\x61nops\"$\n\x0ePredictRequest\x12\x12\n\ninput_data\x18\x01 \x01(\t\"&\n\x0fPredictResponse\x12\x13\n\x0boutput_data\x18\x01 \x01(\t2C\n\x05\x41nOps\x12:\n\x07Predict\x12\x15.anops.PredictRequest\x1a\x16.anops.PredictResponse\"\x00\x62\x06proto3')
⋮----
_globals = globals()
⋮----
# @@protoc_insertion_point(module_scope)
</file>

<file path="api-service/anops_pb2.pyi">
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from typing import ClassVar as _ClassVar, Optional as _Optional

DESCRIPTOR: _descriptor.FileDescriptor

class PredictRequest(_message.Message):
    __slots__ = ("input_data",)
    INPUT_DATA_FIELD_NUMBER: _ClassVar[int]
    input_data: str
    def __init__(self, input_data: _Optional[str] = ...) -> None: ...

class PredictResponse(_message.Message):
    __slots__ = ("output_data",)
    OUTPUT_DATA_FIELD_NUMBER: _ClassVar[int]
    output_data: str
    def __init__(self, output_data: _Optional[str] = ...) -> None: ...
</file>

<file path="api-service/Dockerfile">
# Use an official Python runtime as a parent image
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy the rest of the application code
# This includes main.py and potentially the generated gRPC code
# if it's placed/copied here during the build process.
COPY . .

# Expose the port the app runs on
EXPOSE 8000

# Command to run the application using Uvicorn
# It will look for an object named 'app' in the file 'main.py'
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000"]
</file>

<file path="api-service/main.py">
# Import the generated gRPC classes
# Assumes the generated files (_pb2.py, _pb2_grpc.py) are accessible.
# This might require adjusting PYTHONPATH or copying files during build.
# For simplicity, we'll assume they are in the same directory or PYTHONPATH.
⋮----
app = FastAPI()
⋮----
# Get the model service URL from environment variable
MODEL_SERVICE_URL = os.getenv("MODEL_SERVICE_URL", "localhost:50051")
⋮----
# Pydantic model for request body
class PredictRequestData(BaseModel)
⋮----
input_data: str
⋮----
# Pydantic model for response body
class PredictResponseData(BaseModel)
⋮----
output_data: str
⋮----
@app.post("/predict", response_model=PredictResponseData)
async def predict(request_data: PredictRequestData)
⋮----
# Establish insecure gRPC channel to the model service
# In production, use secure channels (grpc.secure_channel)
⋮----
stub = anops_pb2_grpc.AnOpsStub(channel)
⋮----
# Create the gRPC request message
grpc_request = anops_pb2.PredictRequest(input_data=request_data.input_data)
⋮----
# Make the asynchronous gRPC call
grpc_response = await stub.Predict(grpc_request)
⋮----
# Return the response data
⋮----
@app.get("/health")
async def health_check()
⋮----
# Basic health check endpoint
⋮----
# This block is mainly for local development testing if needed,
# Uvicorn will run the app in the Docker container.
</file>

<file path="api-service/README.md">
# AnOps API Service

## Overview
The AnOps API Service is a RESTful API that provides access to the underlying `model-service` via a simple HTTP interface. It acts as a bridge between standard web requests and the gRPC-based `model-service`.

**Technology Choice:** This service is implemented using **Python** and the **FastAPI** framework. This choice was made for:
*   **Simplicity and Speed:** FastAPI allows for rapid development of robust APIs.
*   **Python Ecosystem:** Leverages the rich Python ecosystem, familiar to the target audience.
*   **Async Support:** Good support for asynchronous operations, beneficial for handling I/O like gRPC calls.
*   **Automatic Docs:** Built-in OpenAPI (Swagger) documentation generation.

## Functionality
*   Receives requests (e.g., JSON payloads) on defined REST endpoints (e.g., `/predict`).
*   Connects to the `model-service` using gRPC (acting as a gRPC client).
*   Forwards the request data to the `model-service` according to the `model-interface` definition.
*   Receives the response from the `model-service`.
*   Formats and returns the response to the original HTTP caller (e.g., as JSON).

## Running the Service
This service is designed to be run as a Docker container. See the `Dockerfile` and the root `docker-compose.yml`.
</file>

<file path="api-service/requirements.txt">
fastapi>=0.95.0,<1.0.0
uvicorn[standard]>=0.20.0,<1.0.0
grpcio>=1.50.0,<2.0.0
grpcio-tools>=1.50.0,<2.0.0
# grpcio-tools is needed only for code generation, not runtime
</file>

<file path="model-interface/anops.proto">
syntax = "proto3";

package anops;

// The AnOps service definition.
service AnOps {
  // Sends input data for prediction.
  rpc Predict (PredictRequest) returns (PredictResponse) {}
}

// The request message containing the input data.
// For simplicity, starting with a generic string input.
// This will likely evolve to support structured data (e.g., JSON string, bytes, etc.).
message PredictRequest {
  string input_data = 1;
}

// The response message containing the prediction result.
// Similarly generic for now.
message PredictResponse {
  string output_data = 1;
}
</file>

<file path="model-interface/README.md">
# AnOps Model Interface (gRPC)

This directory contains the Protocol Buffer (`.proto`) definitions for the gRPC interface used for communication between the `api-service` and the `model-service`.

## Overview

The `api-service` acts as a gRPC client, sending requests to the `model-service`, which acts as a gRPC server implementing the defined service.

## Service Definition

See `anops.proto` for the formal service and message definitions.

## Generating Code Stubs

You will need the `protoc` compiler and the appropriate language-specific plugins (e.g., `grpcio-tools` for Python) to generate client and server code stubs from the `.proto` file.

**Example (Python):**

```bash
pip install grpcio grpcio-tools
python -m grpc_tools.protoc -I. --python_out=../model-service --pyi_out=../model-service --grpc_python_out=../model-service anops.proto
# Adjust output paths as needed
```

This generated code will be used by the `api-service` (client stubs) and `model-service` (server base classes and stubs).
</file>

<file path="model-service/anops_pb2_grpc.py">
# Generated by the gRPC Python protocol compiler plugin. DO NOT EDIT!
"""Client and server classes corresponding to protobuf-defined services."""
⋮----
GRPC_GENERATED_VERSION = '1.71.0'
GRPC_VERSION = grpc.__version__
_version_not_supported = False
⋮----
_version_not_supported = first_version_is_lower(GRPC_VERSION, GRPC_GENERATED_VERSION)
⋮----
_version_not_supported = True
⋮----
class AnOpsStub(object)
⋮----
"""The AnOps service definition.
    """
⋮----
def __init__(self, channel)
⋮----
"""Constructor.

        Args:
            channel: A grpc.Channel.
        """
⋮----
class AnOpsServicer(object)
⋮----
def Predict(self, request, context)
⋮----
"""Sends input data for prediction.
        """
⋮----
def add_AnOpsServicer_to_server(servicer, server)
⋮----
rpc_method_handlers = {
generic_handler = grpc.method_handlers_generic_handler(
⋮----
# This class is part of an EXPERIMENTAL API.
class AnOps(object)
</file>

<file path="model-service/anops_pb2.py">
# -*- coding: utf-8 -*-
# Generated by the protocol buffer compiler.  DO NOT EDIT!
# NO CHECKED-IN PROTOBUF GENCODE
# source: anops.proto
# Protobuf Python Version: 5.29.0
"""Generated protocol buffer code."""
⋮----
# @@protoc_insertion_point(imports)
⋮----
_sym_db = _symbol_database.Default()
⋮----
DESCRIPTOR = _descriptor_pool.Default().AddSerializedFile(b'\n\x0b\x61nops.proto\x12\x05\x61nops\"$\n\x0ePredictRequest\x12\x12\n\ninput_data\x18\x01 \x01(\t\"&\n\x0fPredictResponse\x12\x13\n\x0boutput_data\x18\x01 \x01(\t2C\n\x05\x41nOps\x12:\n\x07Predict\x12\x15.anops.PredictRequest\x1a\x16.anops.PredictResponse\"\x00\x62\x06proto3')
⋮----
_globals = globals()
⋮----
# @@protoc_insertion_point(module_scope)
</file>

<file path="model-service/anops_pb2.pyi">
from google.protobuf import descriptor as _descriptor
from google.protobuf import message as _message
from typing import ClassVar as _ClassVar, Optional as _Optional

DESCRIPTOR: _descriptor.FileDescriptor

class PredictRequest(_message.Message):
    __slots__ = ("input_data",)
    INPUT_DATA_FIELD_NUMBER: _ClassVar[int]
    input_data: str
    def __init__(self, input_data: _Optional[str] = ...) -> None: ...

class PredictResponse(_message.Message):
    __slots__ = ("output_data",)
    OUTPUT_DATA_FIELD_NUMBER: _ClassVar[int]
    output_data: str
    def __init__(self, output_data: _Optional[str] = ...) -> None: ...
</file>

<file path="model-service/Dockerfile">
# Use an official Python runtime as a parent image
FROM python:3.11-slim

# Set the working directory in the container
WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy the gRPC generated code and the service implementation
# Assumes generated code (_pb2.py, _pb2_grpc.py) is in the build context
COPY . .

# Expose the port the gRPC server listens on
EXPOSE 50051

# Command to run the gRPC server
CMD ["python", "server.py"]
</file>

<file path="model-service/README.md">
# AnOps Model Service

## Overview
The AnOps Model Service is responsible for hosting and executing the actual machine learning or statistical model. It exposes a gRPC interface defined in `../model-interface` and listens for requests from the `api-service`.

**Technology Choice:** This service is primarily intended to be implemented in **Python**, leveraging common data science libraries (e.g., scikit-learn, statsmodels, pandas, numpy) and the `grpcio` library for the gRPC server. Support for R (e.g., using Plumber with a gRPC bridge) is a future consideration.

## Functionality
*   Implements the gRPC server interface defined by `../model-interface/anops.proto`.
*   Loads the user-provided model code and any necessary artifacts (e.g., trained model files).
*   Receives prediction requests from the `api-service` via gRPC.
*   Processes the input data using the loaded model.
*   Returns the prediction results back to the `api-service` via gRPC.

## Running the Service
This service is designed to be run as a Docker container. See the `Dockerfile` and the root `docker-compose.yml`. The user's model code and dependencies will be packaged into this container image during the `ao build` process.
</file>

<file path="model-service/requirements.txt">
grpcio>=1.50.0,<2.0.0
grpcio-tools>=1.50.0,<2.0.0
</file>

<file path="model-service/server.py">
import logging  # Added logging
⋮----
# Import the generated classes
⋮----
# Configure basic logging
⋮----
# --- Simple Model Logic --- #
def run_model(input_str: str) -> str
⋮----
"""Placeholder for actual model execution."""
⋮----
# Example: Reverse the input string
output_str = input_str[::-1]
⋮----
# ------------------------ #
⋮----
# Implementation of the AnOps service
class AnOpsServicer(anops_pb2_grpc.AnOpsServicer)
⋮----
"""Provides methods that implement functionality of the AnOps server."""
⋮----
def Predict(self, request, context)
⋮----
"""Handles the Predict RPC call."""
⋮----
# --- Call the model logic --- #
⋮----
output = run_model(request.input_data)
⋮----
return anops_pb2.PredictResponse()  # Return empty response on error
# -------------------------- #
⋮----
# Function to start the server
def serve()
⋮----
server = grpc.server(futures.ThreadPoolExecutor(max_workers=10))
⋮----
port = "[::]:50051"  # Listen on all interfaces, port 50051
⋮----
# Keep the server running
⋮----
time.sleep(86400)  # Keep alive for one day
⋮----
# Note: Ensure you have generated the _pb2.py and _pb2_grpc.py files
# using grpc_tools.protoc before running this server.
# Example command (run from model-interface dir):
# python -m grpc_tools.protoc -I. --python_out=../model-service --pyi_out=../model-service --grpc_python_out=../model-service anops.proto
</file>

<file path=".repomixignore">
# Add patterns to ignore here, one per line
# Example:
# *.log
# tmp/

ACTIONPLAN.md
tmp/
Cargo.lock
target/
</file>

<file path="ao.toml">
[project]
name = "anops-dev"

# Optional sections for check and tasks can be added later
# [check]
# linters = []
# testers = []
#
# [tasks]
# my-task = ["echo hello"]
</file>

<file path="docker-compose.yml">
version: '3.8'

services:
  api-service:
    build: ./api-service
    ports:
      - "8000:8000" # Expose API port
    environment:
      # Example: Point API to the gRPC service
      MODEL_SERVICE_URL: model-service:50051
    depends_on:
      - model-service
    networks:
      - anops-net

  model-service:
    build: ./model-service
    ports:
      - "50051:50051" # Expose gRPC port (optional for external access, needed for API)
    networks:
      - anops-net

networks:
  anops-net:
    driver: bridge
</file>

<file path="README.md">
# AnOps

`AnOps` is an orchestration tool for deploying and managing machine learning models in production. It is designed to simplify the process of deploying models by providing a consistent interface for all models, regardless of their underlying technology or implementation. `AnOps` is built on top of Docker and gRPC, making it easy to deploy and manage models in any environment that supports these technologies.

`AnOps` is specifically designed to be as simple to use as possible, and usable for statistical modelling experts who may not have a strong background in software engineering. It is intended to be used by data scientists, analysts, and other professionals who need to deploy and manage machine learning models in production.

`AnOps` is designed to be extensible and flexible, allowing users to easily add new models or modify existing ones. It is also designed to be easy to use, with a simple command-line interface and a RESTful API that provides access to all of the functionality of the tool.

`AnOps` consists of four components:
1. `ao` CLI
2. `api-service` (REST API)
3. `model-service` (Python- or R-based)
4. `model-interface` (gRPC interface connecting `api-service` and `model-service`)


## `ao` CLI
The `ao` CLI is a convenience tool for managing an AnOps modeling project. It has the following subcommands:
* `init`: Initializes a new AnOps project by creating the necessary directory structure and configuration files, linking the user's local model to the `model-service`, and setting up the `api-service` to use the model.
* `check`: Validates the project structure and configuration files, ensuring that all required files and directories are present and correctly configured. If the model is python-based, it also runs `ruff` and `pytest` to check for linting errors and run unit tests.
* `run`: Executes a task defined in the configuration file, which can include running shell commands or other `ao` commands. This is useful for orchestrating complex workflows in an analytics or modeling project.
* `build`: Builds the `model-service` Docker image using the provided Dockerfile and configuration files. After building, it will lint and run tests/coverage on the model code one last time before pushing the image to a Docker registry.
* `config`: Displays the current configuration settings for the project, including the project name, model type, and any other relevant settings. This is useful for verifying that the project is set up correctly and that all required settings are in place.

## `api-service`
The `api-service` is a RESTful API that provides access to a single endpoint for using models that fulfill the `model-interface` in production. It is implemented as a Docker container so that it can be deployed in any environment that supports Docker. The API is designed to be simple and easy to use, with a focus on providing a consistent interface for all models.

## `model-service`
The `model-service` is a Docker container that runs a model in production. It is designed to be used with the `model-interface` and can be deployed in any environment that supports Docker. The `model-service` is responsible for running the model and providing predictions to the `api-service`.

## `model-interface`
The `model-interface` is a gRPC interface that connects the `api-service` and the `model-service`. It is designed to be simple and easy to use, with a focus on providing a consistent interface for all models. The `model-interface` is responsible for handling requests from the `api-service` and forwarding them to the `model-service`.
</file>

<file path="repomix.config.json">
{
  "input": {
    "maxFileSize": 52428800
  },
  "output": {
    "filePath": "entire-codebase.xml",
    "style": "xml",
    "parsableStyle": false,
    "fileSummary": true,
    "directoryStructure": true,
    "files": true,
    "removeComments": false,
    "removeEmptyLines": false,
    "compress": false,
    "topFilesLength": 5,
    "showLineNumbers": false,
    "copyToClipboard": false,
    "git": {
      "sortByChanges": true,
      "sortByChangesMaxCommits": 100
    }
  },
  "include": [],
  "ignore": {
    "useGitignore": true,
    "useDefaultPatterns": true,
    "customPatterns": []
  },
  "security": {
    "enableSecurityCheck": true
  },
  "tokenCount": {
    "encoding": "o200k_base"
  }
}
</file>

</files>
